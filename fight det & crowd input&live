import serial
from ultralytics import YOLO
import cv2
import numpy as np

# Initialize serial communication with Arduino
ser = serial.Serial("COM4", 9600)  # Replace "COM4" with your Arduino's COM port
print("Serial communication initialized.")

# Load YOLOv8 pose model
model = YOLO('yolov8n-pose.pt')

# Parameters
motion_threshold = 50  # Threshold for significant motion
sustained_frames_threshold = 3  # Frames required to sustain motion for detection
crowd_threshold = 3  # Number of people required to consider it a crowd

# Dictionary to store previous keypoints and motion history for each person
prev_keypoints_dict = {}
motion_history_dict = {}

# Define violence detection function
def detect_violence(keypoints, person_id):
    """
    Detects violence based on keypoints and their movement.
    :param keypoints: Current keypoints array.
    :param person_id: Unique ID for the person.
    :return: Detected violence status as a string.
    """
    if len(keypoints) < 17:  # Ensure all keypoints are detected
        return "No violence detected"

    # Extract keypoints
    left_shoulder, right_shoulder = keypoints[5], keypoints[6]
    left_hip, right_hip = keypoints[11], keypoints[12]

    # Calculate motion
    if person_id in prev_keypoints_dict:
        prev_keypoints = prev_keypoints_dict[person_id]
        shoulder_motion = (
            abs(prev_keypoints[5][1] - left_shoulder[1])
            + abs(prev_keypoints[6][1] - right_shoulder[1])
        )
        hip_motion = (
            abs(prev_keypoints[11][1] - left_hip[1])
            + abs(prev_keypoints[12][1] - right_hip[1])
        )
        total_motion = shoulder_motion + hip_motion
    else:
        total_motion = 0

    # Update motion history
    if person_id not in motion_history_dict:
        motion_history_dict[person_id] = []

    motion_history_dict[person_id].append(total_motion)
    if len(motion_history_dict[person_id]) > sustained_frames_threshold:
        motion_history_dict[person_id].pop(0)

    # Check if sustained motion exceeds threshold
    sustained_motion = sum(
        1 for motion in motion_history_dict[person_id] if motion > motion_threshold
    )
    if sustained_motion >= sustained_frames_threshold:
        return "Violence detected"
    else:
        return "No violence detected"

# Path to the video file
video_path = "all.mp4"  # Replace with your video file path
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("Error: Could not open the video file.")
    exit()

# Resize settings
resize_width = 640  # Desired width
resize_height = 360  # Desired height

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("End of video or error in reading the frame.")
        break

    # Resize the frame
    frame = cv2.resize(frame, (resize_width, resize_height))

    # Perform inference
    results = model(frame)

    # Annotate frame with violence detection
    annotated_frame = results[0].plot()
    if hasattr(results[0], "keypoints"):
        keypoints_all = results[0].keypoints.xy.cpu().numpy()
        person_count = len(keypoints_all)

        # Check if crowd
        if person_count > crowd_threshold:
            cv2.putText(annotated_frame, "Crowd Detected", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
            print("Crowd detected")

        for idx, keypoints in enumerate(keypoints_all):
            person_id = idx  # Use index as person ID
            status = detect_violence(keypoints, person_id)
            prev_keypoints_dict[person_id] = keypoints  # Update previous keypoints for the person

            # Send 'A' to Arduino if violence is detected
            if status == "Violence detected":
                print(f"Violence detected for Person ") #{person_id + 1}
                ser.write(bytearray('A', 'ascii'))  # Send 'A' to Arduino

            # Display status and person ID
            x, y = int(keypoints[0][0]), int(keypoints[0][1])  # Use nose keypoint as reference for text position
            cv2.putText(annotated_frame, f"Person : {status}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,
                        0.6, (0, 255, 0), 2) #{person_id + 1}

    # Display the resized frame
    cv2.imshow('Pose + Violence Detection', annotated_frame)

    # Break loop on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
ser.close()  # Close the serial connection
cv2.destroyAllWindows()

------------------------------------------------------------------------------------------------------

import serial
from ultralytics import YOLO
import cv2
import numpy as np

# Initialize serial communication with Arduino
ser = serial.Serial("COM4", 9600)  # Replace "COM4" with your Arduino's COM port
print("Serial communication initialized.")

# Load YOLOv8 pose model
model = YOLO('yolov8n-pose.pt')

# Parameters
motion_threshold = 50  # Threshold for significant motion
sustained_frames_threshold = 3  # Frames required to sustain motion for detection
crowd_threshold = 3  # Number of people required to consider it a crowd

# Dictionary to store previous keypoints and motion history for each person
prev_keypoints_dict = {}
motion_history_dict = {}

# Define violence detection function
def detect_violence(keypoints, person_id):
    """
    Detects violence based on keypoints and their movement.
    :param keypoints: Current keypoints array.
    :param person_id: Unique ID for the person.
    :return: Detected violence status as a string.
    """
    if len(keypoints) < 17:  # Ensure all keypoints are detected
        return "No violence detected"

    # Extract keypoints
    left_shoulder, right_shoulder = keypoints[5], keypoints[6]
    left_hip, right_hip = keypoints[11], keypoints[12]

    # Calculate motion
    if person_id in prev_keypoints_dict:
        prev_keypoints = prev_keypoints_dict[person_id]
        shoulder_motion = (
            abs(prev_keypoints[5][1] - left_shoulder[1])
            + abs(prev_keypoints[6][1] - right_shoulder[1])
        )
        hip_motion = (
            abs(prev_keypoints[11][1] - left_hip[1])
            + abs(prev_keypoints[12][1] - right_hip[1])
        )
        total_motion = shoulder_motion + hip_motion
    else:
        total_motion = 0

    # Update motion history
    if person_id not in motion_history_dict:
        motion_history_dict[person_id] = []

    motion_history_dict[person_id].append(total_motion)
    if len(motion_history_dict[person_id]) > sustained_frames_threshold:
        motion_history_dict[person_id].pop(0)

    # Check if sustained motion exceeds threshold
    sustained_motion = sum(
        1 for motion in motion_history_dict[person_id] if motion > motion_threshold
    )
    if sustained_motion >= sustained_frames_threshold:
        return "Violence detected"
    else:
        return "No violence detected"

# Open webcam feed
cap = cv2.VideoCapture(0)  # Use default webcam (change to 1 or higher for external webcams)

if not cap.isOpened():
    print("Error: Could not open the webcam.")
    exit()

# Resize settings
resize_width = 640  # Desired width
resize_height = 360  # Desired height

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("Error in reading the webcam feed.")
        break

    # Resize the frame
    frame = cv2.resize(frame, (resize_width, resize_height))

    # Perform inference
    results = model(frame)

    # Annotate frame with violence detection
    annotated_frame = results[0].plot()
    if hasattr(results[0], "keypoints"):
        keypoints_all = results[0].keypoints.xy.cpu().numpy()
        person_count = len(keypoints_all)

        # Check if crowd
        if person_count > crowd_threshold:
            cv2.putText(annotated_frame, "Crowd Detected", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
            print("Crowd detected")

        for idx, keypoints in enumerate(keypoints_all):
            person_id = idx  # Use index as person ID
            status = detect_violence(keypoints, person_id)
            prev_keypoints_dict[person_id] = keypoints  # Update previous keypoints for the person

            # Send 'A' to Arduino if violence is detected
            if status == "Violence detected":
                print(f"Violence detected for Person ") #{person_id + 1}
                ser.write(bytearray('A', 'ascii'))  # Send 'A' to Arduino

            # Display status and person ID
            x, y = int(keypoints[0][0]), int(keypoints[0][1])  # Use nose keypoint as reference for text position
            cv2.putText(annotated_frame, f"Person : {status}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,
                        0.6, (0, 255, 0), 2) #{person_id + 1}

    # Display the resized frame
    cv2.imshow('Pose + Violence Detection', annotated_frame)

    # Break loop on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
ser.close()  # Close the serial connection
cv2.destroyAllWindows()

